{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# GameGuru\n",
        "Grupo: Omega\n",
        "Integrantes:\n",
        "- Jorge Alcalde Piñeiro\n",
        "- Ismael Salgado López\n",
        "- Jose Luis Campo Rivas\n",
        "- Rubén Castillo García\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Nuestra aplicación,GameGuru, es un sistema de recomendación basado en contenido y en sentimientos que recomienda diferentes juegos en base a descripciones , siendo estas influenciadas por la valoración de los juegos. Nuestro sistema tiene 4 formas de funcionar.\n",
        "- 1ª Le puedes pedir que te recomiende juegos parecidos dado uno como base\n",
        "- 2ª Le puedes dar una descripción para que te recomiende juegos basados en esa descripción\n",
        "- 3ª Te permite seleccionar un juego y realizar una valoración entre 1 y 3 ⭐\n",
        "- 4ª Le puedes dar una reseña y a partir de esta el sistema te creará una puntuación acorde a la reseña dada, siendo esta entre 1 y 3 ⭐\n"
      ],
      "metadata": {
        "id": "M7iW_6xoSVRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funcionamiento\n",
        "Para poder ejecutar el menú y funcione todo correctamente, es necesario ejecutar el código de Imports y cada pieza de código con las funciones."
      ],
      "metadata": {
        "id": "v0iMTKI8G0Ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "A continuación se realizarán la importación de los diferentes elementos necesarios. Primero se importa panda para el tratamiento de los datasets, a continuación el dataset de los juegos y el dataset de los comentarios. A partir de ahí se importa todo lo necesario para el sistema basado en contenidos y sentimientos."
      ],
      "metadata": {
        "id": "Zm_ot2dmqGjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "originalData = pd.read_csv('https://raw.githubusercontent.com/alcalde95/abp/main/dataset.csv',delimiter=\";\")\n",
        "coments = pd.read_csv('https://raw.githubusercontent.com/alcalde95/abp/main/comentarios.csv',delimiter=\";\")\n",
        "\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EdBNu-Hp4Fy",
        "outputId": "947ca834-098f-4e29-f107-31b58df02cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación previa de valoraciones\n",
        "A continuación insertamos una nueva columna en el dataset el cual almacenará la puntuación de cada videojuego. Esta puntuación se obtiene como resultado de la división del número de valoraciones de cada videojuego con el resultado de sumar el valor de todas las valoraciones. Estos dos datos se obtienen de un pequeño dataset que hemos generado."
      ],
      "metadata": {
        "id": "CEqiJIetUj_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos el dataset con algunos juegos y el número de valoraciones junto con la suma total de las valoraciones\n",
        "\n",
        "df = pd.DataFrame([['Hades', 2, 3,], ['Dead Cells', 5,10], ['Risk of Rain 2', 8,24]],\n",
        "     index=[0, 1, 2],\n",
        "     columns=['juego', 'numeroValoraciones','sumaTotalValoraciones'])\n",
        "\n",
        "#Insertamos una nueva columna en el dataset. Al principio no hay videojuegos con valoraciones\n",
        "\n",
        "originalData['valorValoracion'] = 0\n",
        "\n",
        "#Insertamos el valor de las puntuaciones a los siguientes juegos\n",
        "\n",
        "originalData.loc[originalData['nombre']=='Hades', 'valorValoracion'] = df.loc[df['juego']=='Hades','sumaTotalValoraciones'].values[0] / df.loc[df['juego']=='Hades','numeroValoraciones'].values[0]\n",
        "originalData.loc[originalData['nombre']=='Dead Cells', 'valorValoracion'] = df.loc[df['juego']=='Dead Cells','sumaTotalValoraciones'].values[0] / df.loc[df['juego']=='Dead Cells','numeroValoraciones'].values[0]\n",
        "originalData.loc[originalData['nombre']=='Risk of Rain 2', 'valorValoracion'] = df.loc[df['juego'] =='Risk of Rain 2','sumaTotalValoraciones'].values[0] / df.loc[df['juego']=='Risk of Rain 2','numeroValoraciones'].values[0]\n",
        "originalData.loc[originalData['nombre']=='Zelda: A Link Between Worlds', 'valorValoracion'] = 2\n",
        "\n"
      ],
      "metadata": {
        "id": "1xOs4tDqjuM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sistema de recomendación basado en juegos del dataset\n",
        "\n",
        "A continuación podemos ver la función encargada de realizar la recomendación de juegos basados en la descripción de un juego previamente almacenado en el dataset.\n",
        "En esta función, primero se realiza una **tokenization**, que consiste en la división de las descripciones en palabras. A continuación se eliminan aquellas palabras que se consideran sin valor, denominadas **stopwords** y tras esto se extrae la raíz de las palabras, llamado **stemmization**.\n",
        "\n",
        "Una vez completado estos tres procesos se crea el **bag-of-words** utilizando TF-IDF y así obtener un array con vectores de frecuencias. Utilizamos la distancia coseno para obtener la distancia con el juego seleccionado.\n",
        "\n",
        "Tras obtener los resultados anteriores, ordenamos basándonos en aquellos que tienen un mayor acierto, le pedimos al usuario que nos indique cuántos juegos quiere mostrar y se los mostramos, mostrando juego y la distancia del juego mostrado al pedido."
      ],
      "metadata": {
        "id": "ikF0ubGSDg3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recomendadorContenido():\n",
        "  ps = PorterStemmer()\n",
        "\n",
        "  preprocessedText = []\n",
        "\n",
        "  for row in originalData.itertuples():\n",
        "\n",
        "      text = word_tokenize(row[9]) ## indice de la columna que contiene el texto\n",
        "      ## Se remueven las stopwords\n",
        "\n",
        "      stops = set(stopwords.words(\"spanish\"))\n",
        "\n",
        "      text = [ps.stem(w) for w in text if not w in stops and w.isalnum()]\n",
        "      text = \" \".join(text)\n",
        "\n",
        "      preprocessedText.append(text)\n",
        "\n",
        "  ## Se añade una nueva columna al dataset con todos los textos procesados\n",
        "  preprocessedData = originalData\n",
        "  preprocessedData['processed_text'] = preprocessedText\n",
        "\n",
        "  ## Se crea la bolsa de palabras\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "  bagOfWordsModel = TfidfVectorizer()\n",
        "  bagOfWordsModel.fit(preprocessedData['processed_text'])\n",
        "  textsBoW= bagOfWordsModel.transform(preprocessedData['processed_text'])\n",
        "\n",
        "  ## Se crea la matriz de distancias\n",
        "  from sklearn.metrics import pairwise_distances\n",
        "\n",
        "  distance_matrix= pairwise_distances(textsBoW,textsBoW ,metric='cosine')\n",
        "\n",
        "  searchTitle = \"Hades\" #Juego base para las recomendaciones\n",
        "  indexOfTitle = preprocessedData[preprocessedData['nombre']==searchTitle].index.values[0]\n",
        "\n",
        "  distance_scores = list(enumerate(distance_matrix[indexOfTitle]))\n",
        "\n",
        "  ordered_scores = sorted(distance_scores, key=lambda x: x[1])\n",
        "  ## Se piden cuántos juegos quiere mostrar\n",
        "  range=int(input(\"Introduzca cuantos juegos desea ver: \"))\n",
        "  top_scores = ordered_scores[1:range+1]\n",
        "\n",
        "  top_indexes = [i[0] for i in top_scores]\n",
        "\n",
        "  puntuaciones = [valor for _, valor in top_scores]\n",
        "\n",
        "   # Obtener las filas de preprocessedData correspondientes a top_indexes\n",
        "  filas_seleccionadas = originalData.loc[top_indexes, ['nombre', 'valorValoracion']]\n",
        "\n",
        "  #Una vez tenemos las filas seleccionadas, las ordenamos por en función de su valoración\n",
        "\n",
        "  filas_seleccionadas = filas_seleccionadas.sort_values('valorValoracion',ascending =False)\n",
        "\n",
        "  #Teniendo las filas ordenadas, tenemos que ordenar las puntuaciones para que así queden ordenados siguiendo la nueva organización de filas_seleccionadas\n",
        "\n",
        "  puntuaciones = [puntuaciones[top_indexes.index(idx)] for idx in filas_seleccionadas.index]\n",
        "\n",
        "\n",
        "  # Mostrar cada fila junto con el valor correspondiente de puntuaciones\n",
        "  for i, (index, (nombre, valor_valoracion)) in enumerate(filas_seleccionadas.iterrows()):\n",
        "    print(f\"{nombre} - Puntuación: {puntuaciones[i]} - Valor Valoración: {valor_valoracion}\")"
      ],
      "metadata": {
        "id": "uXLzteYODn3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sistema de recomendación basada en la descripción dada por el usuario\n",
        "\n",
        "Esta función es prácticamente igual a la anterior, lo que las diferencian es que para poder realizar una recomendación basada en una descripción dada por el usuario, se crea una nueva entrada en el dataset con la descripción, se realizan todos los procesos y a la hora de mostrar los juegos se hacen en relación con la última entrada del dataset que es la introducida la final.\n",
        "\n",
        "Una vez calculado todo, para que quede el dataset limpio se elimina la última fila del dataset."
      ],
      "metadata": {
        "id": "ZhbXlP8cl780"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recomendadorContenidoDescripcion():\n",
        "  ps = PorterStemmer()\n",
        "  global originalData\n",
        "  preprocessedText = []\n",
        "  ## Se crea e inserta la nueva fila\n",
        "  nueva_fila = {\n",
        "    'id': len(originalData),\n",
        "    'nombre': '',\n",
        "    'desarrollador': '',\n",
        "    'jugadores': '',\n",
        "    'genero': '',\n",
        "    'PEGI': '',\n",
        "    'plataforma': '',\n",
        "    'ano_salida': '',\n",
        "    'descripcion': str(input(\"Introduzca la descripcion del juego: \")),\n",
        "\n",
        "  }\n",
        "\n",
        "\n",
        "  indice_nueva_fila = len(originalData)\n",
        "\n",
        "\n",
        "  originalData.loc[indice_nueva_fila] = nueva_fila\n",
        "\n",
        "  originalData.loc[indice_nueva_fila]\n",
        "\n",
        "  for row in originalData.itertuples():\n",
        "\n",
        "      text = word_tokenize(row[9]) ## indice de la columna que contiene el texto\n",
        "      ## Remove stop words\n",
        "\n",
        "      stops = set(stopwords.words(\"spanish\"))\n",
        "\n",
        "      text = [ps.stem(w) for w in text if not w in stops and w.isalnum()]\n",
        "      text = \" \".join(text)\n",
        "\n",
        "      preprocessedText.append(text)\n",
        "\n",
        "\n",
        "\n",
        "  preprocessedData = originalData\n",
        "  preprocessedData['processed_text'] = preprocessedText\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "  bagOfWordsModel = TfidfVectorizer()\n",
        "  bagOfWordsModel.fit(preprocessedData['processed_text'])\n",
        "  textsBoW= bagOfWordsModel.transform(preprocessedData['processed_text'])\n",
        "\n",
        "  from sklearn.metrics import pairwise_distances\n",
        "\n",
        "  distance_matrix= pairwise_distances(textsBoW,textsBoW ,metric='cosine')\n",
        "\n",
        "\n",
        "  indexOfTitle = indice_nueva_fila\n",
        "\n",
        "  distance_scores = list(enumerate(distance_matrix[indexOfTitle]))\n",
        "\n",
        "  ordered_scores = sorted(distance_scores, key=lambda x: x[1])\n",
        "\n",
        "  range=int(input(\"Introduzca cuantos juegos desea ver: \"))\n",
        "  top_scores = ordered_scores[1:range+1]\n",
        "\n",
        "  top_indexes = [i[0] for i in top_scores]\n",
        "\n",
        "  ## Una vez calculado todo, se elimina la última fila\n",
        "  originalData = originalData.drop(1001, axis=0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "  puntuaciones = [valor for _, valor in top_scores]\n",
        "\n",
        "\n",
        "\n",
        "  # Obtener las filas de preprocessedData correspondientes a top_indexes\n",
        "  filas_seleccionadas = originalData.loc[top_indexes, ['nombre', 'valorValoracion']]\n",
        "\n",
        "  #Una vez tenemos las filas seleccionadas, las ordenamos por en función de su valoración\n",
        "\n",
        "  filas_seleccionadas = filas_seleccionadas.sort_values('valorValoracion',ascending =False)\n",
        "\n",
        "  puntuaciones = [puntuaciones[top_indexes.index(idx)] for idx in filas_seleccionadas.index]\n",
        "\n",
        "  # Mostrar cada fila junto con el valor correspondiente de puntuaciones\n",
        "  for i, (index, (nombre, valor_valoracion)) in enumerate(filas_seleccionadas.iterrows()):\n",
        "    print(f\"{nombre} - Puntuación: {puntuaciones[i]} - Valor Valoración: {valor_valoracion}\")"
      ],
      "metadata": {
        "id": "dTwkkaujmBhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de valoración basado en sentimientos\n",
        "\n",
        "Este cuenta con 2 modos, una valoración manual, donde tu puedes poner valoración sólo o puedes indicarle un comentario y que él te genere una valoración en específico\n"
      ],
      "metadata": {
        "id": "KrFTNK1mbns3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar la bolsa de palabras del dataset de comentarios"
      ],
      "metadata": {
        "id": "0UMyAaxNKemc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer();\n",
        "preprocessedComents = []\n",
        "\n",
        "for row in coments.itertuples():\n",
        "  coment = word_tokenize(row[1]) ##Indice de la columna que contiene el comentario\n",
        "  ## Eliminar palabras vacias (stopwords)\n",
        "  stops = set(stopwords.words(\"spanish\"))\n",
        "  coment = [ps.stem(w) for w in coment if not w in stops and w.isalnum()]\n",
        "  coment = \" \".join(coment)\n",
        "\n",
        "  preprocessedComents.append(coment)\n",
        "\n",
        "preprocessedData = coments\n",
        "preprocessedData['processed_coment'] = preprocessedComents\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "bagOfWordsModel = TfidfVectorizer()\n",
        "bagOfWordsModel.fit(preprocessedData['processed_coment'])\n",
        "textsBoW = bagOfWordsModel.transform(preprocessedData['processed_coment'])"
      ],
      "metadata": {
        "id": "N_OnKZ_71FDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento del algoritmo de clasificación"
      ],
      "metadata": {
        "id": "Qy5RKgQYL1ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(textsBoW, preprocessedData['puntuation'], test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "#Modelo de Clasificacion\n",
        "svc = svm.SVC(kernel='linear')\n",
        "#Entrenamiento\n",
        "svc.fit(X_train, y_train)\n",
        "#Evaluacion del modelo en conj. de validacion\n",
        "accuracy_val = svc.score(X_val,y_val)\n",
        "print(f'Accuracy en el conjunto de validacion: {accuracy_val}')\n",
        "#Evaluacion final en el conjunto de prueba\n",
        "accuracy_test = svc.score(X_test, y_test)\n",
        "print(f'Accuracy en el conjunto de prueba: {accuracy_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cpP0rYJBxVg",
        "outputId": "0753bf1d-57c6-4b3f-b887-623088178bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy en el conjunto de validacion: 1.0\n",
            "Accuracy en el conjunto de prueba: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones creadas a partir del sistema algoritmo de clasificación"
      ],
      "metadata": {
        "id": "w65_YfPDd-U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sistemaValoracion():\n",
        "  print(\"1:Valoracion Manual\")\n",
        "  print(\"2:Valoracion Automatica\")\n",
        "  opcion = int(input())\n",
        "\n",
        "  match opcion:\n",
        "    case 1:valoracionManual()\n",
        "    case 2:valoracionAutomatica()"
      ],
      "metadata": {
        "id": "KP3t8Hu1RW0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valoracionAutomatica():\n",
        "\n",
        "  print(\"Introduzca el número del juego que quiere valorar\")\n",
        "  print(originalData[[\"id\",\"nombre\"]])\n",
        "  input()\n",
        "\n",
        "  print(\"* = Malo\")\n",
        "  print(\"** = Neutro\")\n",
        "  print(\"*** = Muy bueno\")\n",
        "\n",
        "  user_comment = input(\"Introduce tu comentario: \")\n",
        "  #Preprocesamiento del comentario de entrada\n",
        "  preprocessed_user_comment = word_tokenize(user_comment)\n",
        "  preprocessed_user_comment = [ps.stem(w) for w in preprocessed_user_comment if not w in stops and w.isalnum()]\n",
        "  preprocessed_user_comment = \" \".join(preprocessed_user_comment)\n",
        "  #Transformacion del comentario usando modelo TF-IDF\n",
        "  user_comment_vector = bagOfWordsModel.transform([preprocessed_user_comment])\n",
        "  #Predicción de puntuacion usando modelo SVM\n",
        "  predicted_punctuation = svc.predict(user_comment_vector)\n",
        "  match predicted_punctuation:\n",
        "    case 1:stars = \"*\"\n",
        "    case 2:stars = \"**\"\n",
        "    case 3:stars = \"***\"\n",
        "  print(\"La valoracion predicha para el comentario es \",stars)"
      ],
      "metadata": {
        "id": "WW3GiyuZFChY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valoracionManual():\n",
        "\n",
        "  print(\"Introduzca el número del juego a  valorar\")\n",
        "  print(originalData[[\"id\",\"nombre\"]])\n",
        "  input()\n",
        "\n",
        "  print(\"* = Malo\")\n",
        "  print(\"** = Neutro\")\n",
        "  print(\"*** = Muy bueno\")\n",
        "\n",
        "  input()"
      ],
      "metadata": {
        "id": "r_0aXDFjS2Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menu:\n",
        "\n",
        "Este es un menú para poder acceder a todas las funcionalidades mostradas.\n",
        "\n",
        "Introduzca 0,1,2 o 3 en función de la funcionalidad a la que quiere acceder."
      ],
      "metadata": {
        "id": "M892nrM4sBvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opcion = 1\n",
        "\n",
        "while opcion != 0:\n",
        "  print(\"0:Exit\")\n",
        "  print(\"1:Recomendador de Contenido\")\n",
        "  print(\"2:Recomendador de Contenido según una descripción\")\n",
        "  print(\"3:Sistema de Valoracion\")\n",
        "  opcion = int(input())\n",
        "\n",
        "  match opcion:\n",
        "    case 1:recomendadorContenido()\n",
        "    case 2:recomendadorContenidoDescripcion()\n",
        "    case 3:sistemaValoracion()\n",
        "## añadir que se muestre el % de acie22rto en la recomendación de contenido\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXs23Lr9rwBw",
        "outputId": "57a64926-e14c-4d23-ca5a-cc77a25ceaed"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:Exit\n",
            "1:Recomendador de Contenido\n",
            "2:Recomendador de Contenido según una descripción\n",
            "3:Sistema de Valoracion\n",
            "1\n",
            "Introduzca cuantos juegos desea ver: 5\n",
            "Risk of Rain 2 - Puntuación: 0.8137709815142152 - Valor Valoración: 3.0\n",
            "Dead Cells - Puntuación: 0.8076785529305041 - Valor Valoración: 2.0\n",
            "Hades - Puntuación: 0.694234112605255 - Valor Valoración: 1.5\n",
            "Hades - Puntuación: 0.694234112605255 - Valor Valoración: 1.5\n",
            "Sparklite - Puntuación: 0.8261883600724826 - Valor Valoración: 0.0\n",
            "0:Exit\n",
            "1:Recomendador de Contenido\n",
            "2:Recomendador de Contenido según una descripción\n",
            "3:Sistema de Valoracion\n",
            "2\n",
            "Introduzca la descripcion del juego: zelda\n",
            "Introduzca cuantos juegos desea ver: 5\n",
            "Zelda: A Link Between Worlds - Puntuación: 0.6772971985261917 - Valor Valoración: 2.0\n",
            "Zelda: Twilight Princess - Puntuación: 0.43575362240240134 - Valor Valoración: 0.0\n",
            "The Legend of Zelda: Breath of the Wild - Puntuación: 1.0 - Valor Valoración: 0.0\n",
            "Red Dead Redemption 2 - Puntuación: 1.0 - Valor Valoración: 0.0\n",
            "The Witcher 3: Wild Hunt - Puntuación: 1.0 - Valor Valoración: 0.0\n",
            "0:Exit\n",
            "1:Recomendador de Contenido\n",
            "2:Recomendador de Contenido según una descripción\n",
            "3:Sistema de Valoracion\n",
            "3\n",
            "1:Valoracion Manual\n",
            "2:Valoracion Automatica\n",
            "2\n",
            "Introduzca el número del juego que quiere valorar\n",
            "        id                                   nombre\n",
            "0        0  The Legend of Zelda: Breath of the Wild\n",
            "1        1                    Red Dead Redemption 2\n",
            "2        2                 The Witcher 3: Wild Hunt\n",
            "3        3                                 Fortnite\n",
            "4        4                                Minecraft\n",
            "...    ...                                      ...\n",
            "996    997                       Six Flags Fun Park\n",
            "997    998                         Two Point Campus\n",
            "998    999             Phoenix Wright: Ace Attorney\n",
            "999   1000           Call Of Duty: Roads To Victory\n",
            "1000  1001                              Odin Sphere\n",
            "\n",
            "[1001 rows x 2 columns]\n",
            "juego horrendo\n",
            "* = Malo\n",
            "** = Neutro\n",
            "*** = Muy bueno\n",
            "Introduce tu comentario: *\n",
            "La valoracion predicha para el comentario es  ***\n",
            "0:Exit\n",
            "1:Recomendador de Contenido\n",
            "2:Recomendador de Contenido según una descripción\n",
            "3:Sistema de Valoracion\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformación a PDF"
      ],
      "metadata": {
        "id": "8Efs3OmCIFQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfkit\n",
        "!apt-get update\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSBEf0lRDRyz",
        "outputId": "316b023c-c2e6-4e57-d125-3f583946132d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfkit\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: pdfkit\n",
            "Successfully installed pdfkit-1.0.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [634 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,599 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,602 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,305 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [50.4 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,326 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,046 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,572 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.8 kB]\n",
            "Fetched 9,570 kB in 2s (5,145 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Monta Google Drive (puedes omitir esto si no necesitas guardar el PDF en Google Drive)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Especifica el nombre del notebook y el nombre del archivo PDF de salida\n",
        "notebook_name = '/content/drive/My Drive/Colab Notebooks/GameGuru.ipynb'\n",
        "output_pdf = '/content/drive/My Drive/Colab Notebooks/GameGuru.ipynb.pdf'  # Cambia la ruta según sea necesario\n",
        "\n",
        "!apt-get install texlive-xetex\n",
        "\n",
        "# Exporta el notebook a PDF utilizando nbconvert\n",
        "!jupyter nbconvert --to pdf \"$notebook_name\"\n",
        "\n",
        "# Copia el PDF a la ubicación deseada en Google Drive\n",
        "shutil.copyfile(notebook_name.replace('.ipynb', '.pdf'), output_pdf)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "NiqOWoZHDrHr",
        "outputId": "aaf81ed0-b10f-4125-9e88-a5c5e2235f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "texlive-xetex is already the newest version (2021.20220204-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
            "[NbConvertApp] Converting notebook /content/drive/My Drive/Colab Notebooks/GameGuru.ipynb to pdf\n",
            "[NbConvertApp] Writing 53639 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 62996 bytes to /content/drive/My Drive/Colab Notebooks/GameGuru.pdf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/GameGuru.ipynb.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliografía:\n",
        "[https://github.com/adrseara/abp_notebooks/blob/master/Tutorial_Recomendador_basado_en_contenido.ipynb](https://github.com/adrseara/abp_notebooks/blob/master/Tutorial_Recomendador_basado_en_contenido.ipynb)\n",
        "[https://github.com/adrseara/abp_notebooks/blob/master/Tutorial_análisis_de_sentimientos.ipynb](https://github.com/adrseara/abp_notebooks/blob/master/Tutorial_análisis_de_sentimientos.ipynb)\n"
      ],
      "metadata": {
        "id": "zNaNJdwPwZCC"
      }
    }
  ]
}